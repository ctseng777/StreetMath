`torch_dtype` is deprecated! Use `dtype` instead!
============================================================
Linear Probing on Dream-v0-Instruct-7B — Target: Near-7
============================================================

========== DREAM: Dream-org/Dream-v0-Instruct-7B ==========
Loading Dream model: Dream-org/Dream-v0-Instruct-7B...
Warning: Error loading with AutoModelForCausalLM: Unrecognized configuration class <class 'transformers_modules.Dream_hyphen_org.Dream_hyphen_v0_hyphen_Instruct_hyphen_7B.05334cb9faaf763692dcf9d8737c642be2b2a6ae.configuration_dream.DreamConfig'> for this kind of AutoModel: AutoModelForCausalLM.
Model type should be one of ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.
Attempting fallback to AutoModel...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:11<00:34, 11.47s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:23<00:24, 12.09s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:34<00:11, 11.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  7.25s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.89s/it]
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Warning: Error getting layer meta: Expected attn_mask dtype to be bool or float or to match query dtype, but got attn_mask.dtype: long int and  query.dtype: c10::Half instead.
Layers: 29 | Width: 3584
  [Progress] Starting stream for 2000 samples (125 batches)...
    Processing batch 10/125...
    Processing batch 20/125...
    Processing batch 30/125...
    Processing batch 40/125...
    Processing batch 50/125...
    Processing batch 60/125...
    Processing batch 70/125...
    Processing batch 80/125...
    Processing batch 90/125...
    Processing batch 100/125...
    Processing batch 110/125...
    Processing batch 120/125...
  [Progress] Starting stream for 2000 samples (125 batches)...
    Processing batch 10/125...
    Processing batch 20/125...
    Processing batch 30/125...
    Processing batch 40/125...
    Processing batch 50/125...
    Processing batch 60/125...
    Processing batch 70/125...
    Processing batch 80/125...
    Processing batch 90/125...
    Processing batch 100/125...
    Processing batch 110/125...
    Processing batch 120/125...
Evaluating digits_paraphrase...
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
  Best layer 6: acc=0.606
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
Evaluating words...
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
  Best layer 2: acc=0.584
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
Done. Results saved to probe_results_dream_near_7.json
