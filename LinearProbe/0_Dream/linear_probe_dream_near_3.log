`torch_dtype` is deprecated! Use `dtype` instead!
============================================================
Linear Probing on Dream-v0-Instruct-7B — Target: Near-3
============================================================

========== DREAM: Dream-org/Dream-v0-Instruct-7B ==========
Loading Dream: Dream-org/Dream-v0-Instruct-7B
Fallback due to: Unrecognized configuration class <class 'transformers_modules.Dream_hyphen_org.Dream_hyphen_v0_hyphen_Instruct_hyphen_7B.05334cb9faaf763692dcf9d8737c642be2b2a6ae.configuration_dream.DreamConfig'> for this kind of AutoModel: AutoModelForCausalLM.
Model type should be one of ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:11<00:33, 11.04s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:23<00:24, 12.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:35<00:11, 11.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  7.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.99s/it]
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
  [Progress] Starting stream for 2000 samples (125 batches)...
    Processing batch 10/125...
    Processing batch 20/125...
    Processing batch 30/125...
    Processing batch 40/125...
    Processing batch 50/125...
    Processing batch 60/125...
    Processing batch 70/125...
    Processing batch 80/125...
    Processing batch 90/125...
    Processing batch 100/125...
    Processing batch 110/125...
    Processing batch 120/125...
  [Progress] Starting stream for 2000 samples (125 batches)...
    Processing batch 10/125...
    Processing batch 20/125...
    Processing batch 30/125...
    Processing batch 40/125...
    Processing batch 50/125...
    Processing batch 60/125...
    Processing batch 70/125...
    Processing batch 80/125...
    Processing batch 90/125...
    Processing batch 100/125...
    Processing batch 110/125...
    Processing batch 120/125...
Evaluating digits_paraphrase...
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
  Best layer 20: acc=0.718
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
Evaluating words...
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
  Best layer 1: acc=0.640
  [Progress] Starting stream for 500 samples (32 batches)...
    Processing batch 10/32...
    Processing batch 20/32...
    Processing batch 30/32...
Done. Results saved to probe_results_dream_near_3.json
