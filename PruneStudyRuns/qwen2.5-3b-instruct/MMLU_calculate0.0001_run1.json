{"mmlu": {"acc,none": 0.6516060133081409, "acc_stderr,none": 0.004111184179240463, "alias": "mmlu"}, "mmlu_humanities": {"acc,none": 0.6291208791208791, "acc_stderr,none": 0.00779741867744568, "alias": " - humanities"}, "mmlu_formal_logic": {"alias": "  - formal_logic", "acc,none": 0.4444444444444444, "acc_stderr,none": 0.044444444444444446}, "mmlu_high_school_european_history": {"alias": "  - high_school_european_history", "acc,none": 0.7818181818181819, "acc_stderr,none": 0.032250781083062896}, "mmlu_high_school_us_history": {"alias": "  - high_school_us_history", "acc,none": 0.8382352941176471, "acc_stderr,none": 0.025845017986926906}, "mmlu_high_school_world_history": {"alias": "  - high_school_world_history", "acc,none": 0.8312236286919831, "acc_stderr,none": 0.02438140683258622}, "mmlu_international_law": {"alias": "  - international_law", "acc,none": 0.7603305785123967, "acc_stderr,none": 0.038968789850704115}, "mmlu_jurisprudence": {"alias": "  - jurisprudence", "acc,none": 0.7962962962962963, "acc_stderr,none": 0.038935425188248496}, "mmlu_logical_fallacies": {"alias": "  - logical_fallacies", "acc,none": 0.7852760736196319, "acc_stderr,none": 0.032262193772867716}, "mmlu_moral_disputes": {"alias": "  - moral_disputes", "acc,none": 0.6734104046242775, "acc_stderr,none": 0.02524826477424287}, "mmlu_moral_scenarios": {"alias": "  - moral_scenarios", "acc,none": 0.318, "acc_stderr,none": 0.020847571620814014}, "mmlu_philosophy": {"alias": "  - philosophy", "acc,none": 0.7041800643086816, "acc_stderr,none": 0.025922371788818833}, "mmlu_prehistory": {"alias": "  - prehistory", "acc,none": 0.7253086419753086, "acc_stderr,none": 0.024836057868294684}, "mmlu_professional_law": {"alias": "  - professional_law", "acc,none": 0.434, "acc_stderr,none": 0.02218721580302901}, "mmlu_world_religions": {"alias": "  - world_religions", "acc,none": 0.8128654970760234, "acc_stderr,none": 0.029913127232368063}, "mmlu_other": {"acc,none": 0.6876770538243626, "acc_stderr,none": 0.008497649919769838, "alias": " - other"}, "mmlu_business_ethics": {"alias": "  - business_ethics", "acc,none": 0.74, "acc_stderr,none": 0.0440844002276808}, "mmlu_clinical_knowledge": {"alias": "  - clinical_knowledge", "acc,none": 0.7132075471698113, "acc_stderr,none": 0.027834912527544126}, "mmlu_college_medicine": {"alias": "  - college_medicine", "acc,none": 0.6705202312138728, "acc_stderr,none": 0.03583901754736415}, "mmlu_global_facts": {"alias": "  - global_facts", "acc,none": 0.37, "acc_stderr,none": 0.048523658709390974}, "mmlu_human_aging": {"alias": "  - human_aging", "acc,none": 0.6816143497757847, "acc_stderr,none": 0.03126580522513711}, "mmlu_management": {"alias": "  - management", "acc,none": 0.7572815533980582, "acc_stderr,none": 0.04245022486384496}, "mmlu_marketing": {"alias": "  - marketing", "acc,none": 0.8632478632478633, "acc_stderr,none": 0.022509033937077844}, "mmlu_medical_genetics": {"alias": "  - medical_genetics", "acc,none": 0.73, "acc_stderr,none": 0.04461960433384737}, "mmlu_miscellaneous": {"alias": "  - miscellaneous", "acc,none": 0.772, "acc_stderr,none": 0.018781306529363172}, "mmlu_nutrition": {"alias": "  - nutrition", "acc,none": 0.7156862745098039, "acc_stderr,none": 0.025829163272757385}, "mmlu_professional_accounting": {"alias": "  - professional_accounting", "acc,none": 0.5319148936170213, "acc_stderr,none": 0.02976667507587383}, "mmlu_professional_medicine": {"alias": "  - professional_medicine", "acc,none": 0.6507352941176471, "acc_stderr,none": 0.02895975519682485}, "mmlu_virology": {"alias": "  - virology", "acc,none": 0.536144578313253, "acc_stderr,none": 0.038823108508905954}, "mmlu_social_sciences": {"acc,none": 0.739041095890411, "acc_stderr,none": 0.008007180533437646, "alias": " - social sciences"}, "mmlu_econometrics": {"alias": "  - econometrics", "acc,none": 0.49122807017543857, "acc_stderr,none": 0.0470288043204961}, "mmlu_high_school_geography": {"alias": "  - high_school_geography", "acc,none": 0.7575757575757576, "acc_stderr,none": 0.030532892233932022}, "mmlu_high_school_government_and_politics": {"alias": "  - high_school_government_and_politics", "acc,none": 0.844559585492228, "acc_stderr,none": 0.026148483469153303}, "mmlu_high_school_macroeconomics": {"alias": "  - high_school_macroeconomics", "acc,none": 0.6666666666666666, "acc_stderr,none": 0.023901157979402492}, "mmlu_high_school_microeconomics": {"alias": "  - high_school_microeconomics", "acc,none": 0.7394957983193278, "acc_stderr,none": 0.028510251512341933}, "mmlu_high_school_psychology": {"alias": "  - high_school_psychology", "acc,none": 0.836, "acc_stderr,none": 0.016575811142446696}, "mmlu_human_sexuality": {"alias": "  - human_sexuality", "acc,none": 0.7480916030534351, "acc_stderr,none": 0.03807387116306089}, "mmlu_professional_psychology": {"alias": "  - professional_psychology", "acc,none": 0.694, "acc_stderr,none": 0.020629569998345417}, "mmlu_public_relations": {"alias": "  - public_relations", "acc,none": 0.6636363636363637, "acc_stderr,none": 0.04525393596302509}, "mmlu_security_studies": {"alias": "  - security_studies", "acc,none": 0.7224489795918367, "acc_stderr,none": 0.028666857790274648}, "mmlu_sociology": {"alias": "  - sociology", "acc,none": 0.7910447761194029, "acc_stderr,none": 0.02874829893172869}, "mmlu_us_foreign_policy": {"alias": "  - us_foreign_policy", "acc,none": 0.81, "acc_stderr,none": 0.039427724440366255}, "mmlu_stem": {"acc,none": 0.5616872819536949, "acc_stderr,none": 0.008567067761723328, "alias": " - stem"}, "mmlu_abstract_algebra": {"alias": "  - abstract_algebra", "acc,none": 0.35, "acc_stderr,none": 0.04793724854411023}, "mmlu_anatomy": {"alias": "  - anatomy", "acc,none": 0.6148148148148148, "acc_stderr,none": 0.042039210401562783}, "mmlu_astronomy": {"alias": "  - astronomy", "acc,none": 0.6578947368421053, "acc_stderr,none": 0.0386073159931609}, "mmlu_college_biology": {"alias": "  - college_biology", "acc,none": 0.7083333333333334, "acc_stderr,none": 0.03800968060554863}, "mmlu_college_chemistry": {"alias": "  - college_chemistry", "acc,none": 0.4, "acc_stderr,none": 0.0492365963917331}, "mmlu_college_computer_science": {"alias": "  - college_computer_science", "acc,none": 0.52, "acc_stderr,none": 0.05021167315686783}, "mmlu_college_mathematics": {"alias": "  - college_mathematics", "acc,none": 0.35, "acc_stderr,none": 0.04793724854411023}, "mmlu_college_physics": {"alias": "  - college_physics", "acc,none": 0.4803921568627451, "acc_stderr,none": 0.04971358884367401}, "mmlu_computer_security": {"alias": "  - computer_security", "acc,none": 0.75, "acc_stderr,none": 0.04351941398892446}, "mmlu_conceptual_physics": {"alias": "  - conceptual_physics", "acc,none": 0.6170212765957447, "acc_stderr,none": 0.03177821250236923}, "mmlu_electrical_engineering": {"alias": "  - electrical_engineering", "acc,none": 0.6482758620689655, "acc_stderr,none": 0.03979236637497416}, "mmlu_elementary_mathematics": {"alias": "  - elementary_mathematics", "acc,none": 0.4894179894179894, "acc_stderr,none": 0.02574554227604548}, "mmlu_high_school_biology": {"alias": "  - high_school_biology", "acc,none": 0.7580645161290323, "acc_stderr,none": 0.024362599693031024}, "mmlu_high_school_chemistry": {"alias": "  - high_school_chemistry", "acc,none": 0.5369458128078818, "acc_stderr,none": 0.03508370520442665}, "mmlu_high_school_computer_science": {"alias": "  - high_school_computer_science", "acc,none": 0.72, "acc_stderr,none": 0.045126085985421296}, "mmlu_high_school_mathematics": {"alias": "  - high_school_mathematics", "acc,none": 0.4074074074074074, "acc_stderr,none": 0.02995824925008211}, "mmlu_high_school_physics": {"alias": "  - high_school_physics", "acc,none": 0.423841059602649, "acc_stderr,none": 0.04034846678603395}, "mmlu_high_school_statistics": {"alias": "  - high_school_statistics", "acc,none": 0.6296296296296297, "acc_stderr,none": 0.03293377139415187}, "mmlu_machine_learning": {"alias": "  - machine_learning", "acc,none": 0.44642857142857145, "acc_stderr,none": 0.04718471485219583}}